{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Pre-Processing Toolkit.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37puETfgRzzg",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoRP98MpR-qj",
        "colab_type": "text"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_oAO81YuUt-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing three python libraries for preprocessing; refer to the libraries with their name for e.g. \"np\"\n",
        "#numpy --> arrays & scientific computing\n",
        "#matplotlib.pyplot --> graphs and plotting\n",
        "#pandas --> machine learning and data analysis\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RopL7tUZSQkT",
        "colab_type": "text"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBvz81DFvHu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#If using Google Colab, add the csv file before reading.\n",
        "#X is the matrix of features.\n",
        "#Y is the vector of the dependent variable (what we're predicting)\n",
        "\n",
        "dataset = pd.read_csv('Data.csv') \n",
        "X = dataset.iloc[:, :-1].values #selecting all rows and all columns except the last one\n",
        "Y = dataset.iloc[:, -1].values #selecting all rows in the last column"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sFtc-JAx0Ow",
        "colab_type": "code",
        "outputId": "6238dce5-9cc0-4764-e165-e71593534985",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 nan]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' nan 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjU2a0wRx-03",
        "colab_type": "code",
        "outputId": "f3cf7066-234a-4fa2-f04a-30a59f771430",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(Y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhfKXNxlSabC",
        "colab_type": "text"
      },
      "source": [
        "## Taking care of missing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toAisIMEy1yu",
        "colab_type": "code",
        "outputId": "b5902e21-6272-4007-f3b5-8774387fe420",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#sklearn is a machine learning library. \n",
        "#imputer is best for assigning data to missing values.\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean') #replacement data is the mean value\n",
        "imputer.fit(X[:, 1:3]) #imputer function calculates mean value of feature matrix\n",
        "X[:, 1:3] = imputer.transform(X[:, 1:3]) #applying imputer transformation on feature matrix\n",
        "print(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 63777.77777777778]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' 38.77777777777778 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CriG6VzVSjcK",
        "colab_type": "text"
      },
      "source": [
        "## Encoding categorical data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp4-yNpm7GSW",
        "colab_type": "text"
      },
      "source": [
        "### Encoding the independent variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8mUtIC6ZaaW",
        "colab_type": "code",
        "outputId": "f09793da-9445-476f-dd3b-f32a91ca2b36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#Three unique values in countries are transformed into three separate columns.\n",
        "#France is represented by 100, Spain by 001 and Germany by 010.\n",
        "#normal digits aren't used (e.g. 1, 2,3) because the model might consider the countries as being ordered.\n",
        "#remainder = \"passthrough\" enables the untransformed columns (age and salary) to be left unchanged.\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers= [('encoder', OneHotEncoder(), [0])], remainder= 'passthrough')\n",
        "X = np.array(ct.fit_transform(X))\n",
        "print(X)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 35.0 58000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhSpdQWeSsFh",
        "colab_type": "text"
      },
      "source": [
        "### Encoding the Dependent Variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5frvAnYdIzk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Labelling the Yes/No values of the dependent variable as 0 and 1 bits.\n",
        "\n",
        "from sklearn.preprocessing import  LabelEncoder\n",
        "le = LabelEncoder()\n",
        "Y = le.fit_transform(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLDd7ztkdfFP",
        "colab_type": "code",
        "outputId": "656583d6-137d-4d5a-bad1-8e83e4c2a161",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(Y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb_vcgm3qZKW",
        "colab_type": "text"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEFs--Y1eFpi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training set is the segment of data set that will be used to train the ML model.\n",
        "#Test set is the segment used to check whether the model works correctly. If the model accurately\n",
        "#predicts the dependent variable values in the test set, then it is working correctly.\n",
        "#test_size is split size. 0.2 means 20% of observations in both X and Y will go into the test set.\n",
        "#random_state can be assigned to any number for e.g. 0, 1, 2 etc. this is so that every time the code is refreshed same features are extracted. \n",
        "#random_state = None would cause different feature extraction upon every refresh\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 1)  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16B96FWS25k3",
        "colab_type": "code",
        "outputId": "4a81636f-8cc3-4123-9e96-9f1a6aa0f1ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "print(x_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 35.0 58000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH1EcMin27No",
        "colab_type": "code",
        "outputId": "da9ccd80-fd6a-42da-ba39-f723f162678c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 0 0 1 1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DnPvRpL25jB",
        "colab_type": "code",
        "outputId": "b09c5129-d676-4bf2-db86-5b72d2d4915b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(x_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0 1.0 0.0 30.0 54000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jmnexby25dK",
        "colab_type": "code",
        "outputId": "b19927cb-2522-4dd0-aa32-45a457f8d432",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpGqbS4TqkIR",
        "colab_type": "text"
      },
      "source": [
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yn-Q_C2Wjoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#In some datasets, some features get more values than others (dominates them). \n",
        "#Dominated features may not be considered by the model.\n",
        "#Feature scaling is used to prevent this concept. There are two main techniques: Normalization and Standardization\n",
        "#Use normalization if features are distributed normally ( a normal curve); or else use standardiazation\n",
        "\n",
        "#Standardization usually transforms values into something between -3 and 3. Do not standardize dummy variables\n",
        "#(for e.g. country bits) because if you do, dummy variables will lose meaning. And since they are already in the range,\n",
        "#applying standardization is not necessary. In this data, Age and Salary need to be scaled. \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "x_train[:, 3:] = sc.fit_transform(x_train[:, 3:]) #in fit_transform, calculation and application done at the same time.\n",
        "x_test[:, 3:] = sc.transform(x_test[:, 3:]) #only apply transformation to test set, since calculation of scalar already done with the training set.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gML2R6yQSA4U",
        "colab_type": "code",
        "outputId": "d8009345-2bdc-481c-b915-9fde6db71494",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "print(x_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0 0.0 1.0 -0.19159184384578545 -1.0781259408412425]\n",
            " [0.0 1.0 0.0 -0.014117293757057777 -0.07013167641635372]\n",
            " [1.0 0.0 0.0 0.566708506533324 0.633562432710455]\n",
            " [0.0 0.0 1.0 -0.30453019390224867 -0.30786617274297867]\n",
            " [0.0 0.0 1.0 -1.9018011447007988 -1.420463615551582]\n",
            " [1.0 0.0 0.0 1.1475343068237058 1.232653363453549]\n",
            " [0.0 1.0 0.0 1.4379472069688968 1.5749910381638885]\n",
            " [1.0 0.0 0.0 -0.7401495441200351 -0.5646194287757332]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_Dwd0JfSA7o",
        "colab_type": "code",
        "outputId": "cbff53f0-6ee5-475e-e84a-8db468f93c0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(x_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0 1.0 0.0 -1.4661817944830124 -0.9069571034860727]\n",
            " [1.0 0.0 0.0 -0.44973664397484414 0.2056403393225306]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}