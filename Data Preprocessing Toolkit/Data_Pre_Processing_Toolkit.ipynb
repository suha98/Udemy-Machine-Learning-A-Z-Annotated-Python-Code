{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Pre-Processing Toolkit.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37puETfgRzzg",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing Tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoRP98MpR-qj",
        "colab_type": "text"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_oAO81YuUt-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing three python libraries for preprocessing; refer to the libraries with their name for e.g. \"np\"\n",
        "#numpy --> arrays & scientific computing\n",
        "#matplotlib.pyplot --> graphs and plotting\n",
        "#pandas --> machine learning and data analysis\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RopL7tUZSQkT",
        "colab_type": "text"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBvz81DFvHu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#If using Google Colab, add the csv file before reading.\n",
        "#X is the matrix of features.\n",
        "#Y is the vector of the dependent variable (what we're predicting)\n",
        "\n",
        "dataset = pd.read_csv('Data.csv') \n",
        "X = dataset.iloc[:, :-1].values #selecting all rows and all columns except the last one\n",
        "Y = dataset.iloc[:, -1].values #selecting all rows in the last column"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sFtc-JAx0Ow",
        "colab_type": "code",
        "outputId": "197d3b90-6abb-4eda-ae5b-bc760574de3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 nan]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' nan 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjU2a0wRx-03",
        "colab_type": "code",
        "outputId": "535ad40b-584a-49c0-d6c4-dafefa6c3211",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(Y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhfKXNxlSabC",
        "colab_type": "text"
      },
      "source": [
        "## Taking care of missing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toAisIMEy1yu",
        "colab_type": "code",
        "outputId": "02b15d41-a3cf-4bd7-df35-aa0ab25ae7bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#sklearn is a machine learning library. \n",
        "#imputer is best for assigning data to missing values.\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean') #replacement data is the mean value\n",
        "imputer.fit(X[:, 1:3]) #imputer function calculates mean value of feature matrix\n",
        "X[:, 1:3] = imputer.transform(X[:, 1:3]) #applying imputer transformation on feature matrix\n",
        "print(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 63777.77777777778]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' 38.77777777777778 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CriG6VzVSjcK",
        "colab_type": "text"
      },
      "source": [
        "## Encoding categorical data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp4-yNpm7GSW",
        "colab_type": "text"
      },
      "source": [
        "### Encoding the independent variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8mUtIC6ZaaW",
        "colab_type": "code",
        "outputId": "8d4f8630-2758-4701-ee5f-1bd9f4606b14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#Three unique values in countries are transformed into three separate columns.\n",
        "#France is represented by 100, Spain by 001 and Germany by 010.\n",
        "#normal digits aren't used (e.g. 1, 2,3) because the model might consider the countries as being ordered.\n",
        "#remainder = \"passthrough\" enables the untransformed columns (age and salary) to be left unchanged.\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers= [('encoder', OneHotEncoder(), [0])], remainder= 'passthrough')\n",
        "X = np.array(ct.fit_transform(X))\n",
        "print(X)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 35.0 58000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhSpdQWeSsFh",
        "colab_type": "text"
      },
      "source": [
        "### Encoding the Dependent Variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5frvAnYdIzk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Labelling the Yes/No values of the dependent variable as 0 and 1 bits.\n",
        "\n",
        "from sklearn.preprocessing import  LabelEncoder\n",
        "le = LabelEncoder()\n",
        "Y = le.fit_transform(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLDd7ztkdfFP",
        "colab_type": "code",
        "outputId": "2dbbe565-d00d-439d-fe28-683f3092e5d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(Y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb_vcgm3qZKW",
        "colab_type": "text"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEFs--Y1eFpi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training set is the segment of data set that will be used to train the ML model.\n",
        "#Test set is the segment used to check whether the model works correctly. If the model accurately\n",
        "#predicts the dependent variable values in the test set, then it is working correctly.\n",
        "#test_size is split size. 0.2 means 20% of observations in both X and Y will go into the test set.\n",
        "##random_state = 1 means that we get the same random factors from both X and Y.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 1)  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16B96FWS25k3",
        "colab_type": "code",
        "outputId": "13d38e11-b0fc-4c6d-d48b-9c1e87b4b930",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "print(x_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 35.0 58000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH1EcMin27No",
        "colab_type": "code",
        "outputId": "8e15fe13-1c10-4a7e-d1b6-126d02cdfb40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 0 0 1 1 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DnPvRpL25jB",
        "colab_type": "code",
        "outputId": "04ed9abc-130d-44f5-cd13-c78d06633ea9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(x_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0 1.0 0.0 30.0 54000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jmnexby25dK",
        "colab_type": "code",
        "outputId": "b61bfd2b-0f18-4f8a-cc34-9464709ee737",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpGqbS4TqkIR",
        "colab_type": "text"
      },
      "source": [
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzkZKYKzHuCZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#In some datasets, some features get more values than others (dominates them). \n",
        "#Dominated features may not be considered by the model.\n",
        "#Feature scaling is used to prevent this concept. There are two main techniques: Normalization and Standardization\n",
        "#Use normalization if features are distributed normally ( a normal curve); or else use standardiazation\n",
        "\n",
        "#Standardization usually transforms values into something between -3 and 3. Do not standardize dummy variables\n",
        "#(for e.g. country bits) because if you do, dummy variables will lose meaning. And since they are already in the range,\n",
        "#applying standardization is not necessary.\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}